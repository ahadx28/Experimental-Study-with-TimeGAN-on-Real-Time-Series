{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdcc452a",
   "metadata": {},
   "source": [
    "# Advanced diagnostics: real vs synthetic electricity windows\n",
    "\n",
    "This notebook runs STL decomposition, change-point detection, and lagged cross-correlation on example windows and saves figures + a JSON summary to `outputs/figures/diagnostics/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ff2a7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"C:\\BDA_CEP_Part-2\")\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# required libs: statsmodels, ruptures\n",
    "try:\n",
    "    from statsmodels.tsa.seasonal import STL\n",
    "except Exception as e:\n",
    "    raise SystemExit(\"Please install statsmodels (pip install statsmodels). Error: \" + str(e))\n",
    "try:\n",
    "    import ruptures as rpt\n",
    "except Exception as e:\n",
    "    raise SystemExit(\"Please install ruptures (pip install ruptures). Error: \" + str(e))\n",
    "\n",
    "# reproducibility for any shuffles/sampling (not strictly needed here but handy)\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62cd2ba",
   "metadata": {},
   "source": [
    "## Paths, output directory, and file checks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaa89f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required files found. Outputs will go to: outputs/figures/diagnostics\n"
     ]
    }
   ],
   "source": [
    "OUT_DIR = \"outputs/figures/diagnostics\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "DATA_DIR = \"data/processed/electricity\"\n",
    "SYN_PATH = \"outputs/synth/synth_electricity_2000w.npy\"   # inverse-scaled synth\n",
    "\n",
    "# quick sanity checks\n",
    "for p in [\n",
    "    os.path.join(DATA_DIR, \"test.npy\"),\n",
    "    os.path.join(DATA_DIR, \"scalers.pkl\"),\n",
    "    os.path.join(DATA_DIR, \"features.txt\"),\n",
    "    SYN_PATH\n",
    "]:\n",
    "    if not os.path.exists(p):\n",
    "        raise FileNotFoundError(f\"Required file not found: {p}\")\n",
    "print(\"All required files found. Outputs will go to:\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e96841",
   "metadata": {},
   "source": [
    "## Load data and (un)scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc203dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded shapes -> real_scaled: (216, 168, 7) real_orig: (216, 168, 7) synth_inv: (2000, 168, 7)\n"
     ]
    }
   ],
   "source": [
    "# load scaled real and scaler (we'll inverse transform real into original units)\n",
    "real_scaled = np.load(os.path.join(DATA_DIR, \"test.npy\"))    # scaled\n",
    "with open(os.path.join(DATA_DIR, \"scalers.pkl\"), \"rb\") as f:\n",
    "    scalers = pickle.load(f)  # This is a list of scalers\n",
    "\n",
    "# convert scaled real back to original units for human-meaningful plots\n",
    "n_real, T, D = real_scaled.shape\n",
    "real_orig = np.zeros_like(real_scaled)\n",
    "\n",
    "# Apply inverse transform for each feature\n",
    "for feature_idx in range(D):\n",
    "    feature_data = real_scaled[:, :, feature_idx].reshape(-1, 1)\n",
    "    orig_feature = scalers[feature_idx].inverse_transform(feature_data)\n",
    "    real_orig[:, :, feature_idx] = orig_feature.reshape(n_real, T)\n",
    "\n",
    "# load synth (inverse-scaled already in original units)\n",
    "synth_inv = np.load(SYN_PATH)\n",
    "\n",
    "# create scaled synth too (for any comparisons in scaled space)\n",
    "synth_scaled = np.zeros_like(synth_inv)\n",
    "\n",
    "# Apply transform for each feature to scale synth data\n",
    "for feature_idx in range(D):\n",
    "    feature_data = synth_inv[:, :, feature_idx].reshape(-1, 1)\n",
    "    scaled_feature = scalers[feature_idx].transform(feature_data)\n",
    "    synth_scaled[:, :, feature_idx] = scaled_feature.reshape(synth_inv.shape[0], synth_inv.shape[1])\n",
    "\n",
    "FEATURE_NAMES = open(os.path.join(DATA_DIR, \"features.txt\")).read().splitlines()\n",
    "print(\"Loaded shapes -> real_scaled:\", real_scaled.shape, \"real_orig:\", real_orig.shape, \"synth_inv:\", synth_inv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b616c6",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "- STL decomposition + plot\n",
    "- change-point detection (ruptures PELT with RBF)\n",
    "- plotting change-points\n",
    "- lagged cross-correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b53d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERIOD = 24   # hourly data with daily seasonality\n",
    "CHANGEPOINT_PEN = 10  # penalty for ruptures; adjust if too many/few CPs\n",
    "MAX_LAG = 48  # for lagged cross-correlation (hours)\n",
    "\n",
    "def stl_and_plot(series, title_prefix, out_png, period=PERIOD):\n",
    "    \"\"\"Compute STL and save a figure. Returns small metadata dict.\"\"\"\n",
    "    stl = STL(series, period=period, robust=True)\n",
    "    res = stl.fit()\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(10, 7), sharex=True)\n",
    "    axes[0].plot(res.trend); axes[0].set_title(f\"{title_prefix} — Trend\")\n",
    "    axes[1].plot(res.seasonal); axes[1].set_title(f\"{title_prefix} — Seasonal\")\n",
    "    axes[2].plot(res.resid); axes[2].set_title(f\"{title_prefix} — Residual\")\n",
    "    axes[3].plot(series); axes[3].set_title(f\"{title_prefix} — Original\")\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(out_png, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    return {\"trend_mean\": float(np.nanmean(res.trend)), \"seasonal_std\": float(np.nanstd(res.seasonal))}\n",
    "\n",
    "def detect_changepoints(series, pen=CHANGEPOINT_PEN):\n",
    "    \"\"\"Return list of change-point indices using PELT with RBF.\"\"\"\n",
    "    algo = rpt.Pelt(model=\"rbf\").fit(series)\n",
    "    try:\n",
    "        cps = algo.predict(pen=pen)\n",
    "    except Exception:\n",
    "        # fallback to a small fixed number of breakpoints\n",
    "        cps = algo.predict(n_bkps=3)\n",
    "    return cps\n",
    "\n",
    "def plot_changepoints(series, cps, title, out_png):\n",
    "    fig, ax = plt.subplots(figsize=(10, 3))\n",
    "    ax.plot(series, label=title)\n",
    "    for cp in cps[:-1]:\n",
    "        ax.axvline(cp, color='red', linestyle='--', alpha=0.7)\n",
    "    ax.set_title(title + \" (change-points dashed)\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(out_png, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def lagged_corr(x, y, max_lag=MAX_LAG):\n",
    "    lags = list(range(-max_lag, max_lag + 1))\n",
    "    corrs = []\n",
    "    for lag in lags:\n",
    "        if lag < 0:\n",
    "            a = x[:lag]; b = y[-lag:]\n",
    "        elif lag > 0:\n",
    "            a = x[lag:]; b = y[:-lag]\n",
    "        else:\n",
    "            a = x; b = y\n",
    "        if a.size == 0 or b.size == 0:\n",
    "            corrs.append(0.0)\n",
    "        else:\n",
    "            c = np.corrcoef(a, b)[0, 1]\n",
    "            corrs.append(0.0 if np.isnan(c) else float(c))\n",
    "    return np.array(lags), np.array(corrs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74299181",
   "metadata": {},
   "source": [
    "## Run diagnostics for example windows\n",
    "- STL + CPD for all features in each example window\n",
    "- Lagged cross-correlation for selected feature pairs\n",
    "- Summary JSON with CP counts will be saved in OUT_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9aa73fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagnostics complete. Plots & JSON summary saved to: outputs/figures/diagnostics\n"
     ]
    }
   ],
   "source": [
    "EXAMPLES = 3  # number of windows to analyze side-by-side (first EXAMPLES windows)\n",
    "feature_pairs = [(0, 1), (0, 2)]   # pairs to compute lagged cross-correlation\n",
    "num_examples = min(EXAMPLES, n_real, synth_inv.shape[0])\n",
    "\n",
    "summary = {\"windows\": []}\n",
    "\n",
    "for i in range(num_examples):\n",
    "    win_summary = {\"index\": int(i), \"features\": {}}\n",
    "    for fi in range(D):\n",
    "        fname = FEATURE_NAMES[fi] if fi < len(FEATURE_NAMES) else f\"f{fi}\"\n",
    "        # pick series for real and synth (original units)\n",
    "        s_real = real_orig[i, :, fi]\n",
    "        s_synth = synth_inv[i, :, fi]  # synth_inv already in original units\n",
    "\n",
    "        # 1) STL decomposition and plot\n",
    "        out_r = os.path.join(OUT_DIR, f\"stl_real_win{i}_feat{fi}_{fname}.png\")\n",
    "        out_s = os.path.join(OUT_DIR, f\"stl_synth_win{i}_feat{fi}_{fname}.png\")\n",
    "        meta_r = stl_and_plot(s_real, f\"Real win{i} {fname}\", out_r)\n",
    "        meta_s = stl_and_plot(s_synth, f\"Synth win{i} {fname}\", out_s)\n",
    "        win_summary[\"features\"][fname] = {\"stl_real\": meta_r, \"stl_synth\": meta_s}\n",
    "\n",
    "        # 2) change-point detection\n",
    "        cps_r = detect_changepoints(s_real)\n",
    "        cps_s = detect_changepoints(s_synth)\n",
    "        plot_changepoints(s_real, cps_r, f\"Real win{i} {fname}\", os.path.join(OUT_DIR, f\"cp_real_win{i}_feat{fi}_{fname}.png\"))\n",
    "        plot_changepoints(s_synth, cps_s, f\"Synth win{i} {fname}\", os.path.join(OUT_DIR, f\"cp_synth_win{i}_feat{fi}_{fname}.png\"))\n",
    "        win_summary[\"features\"][fname].update({\"cps_real\": cps_r, \"cps_synth\": cps_s})\n",
    "\n",
    "    # 3) lagged cross-correlations for chosen feature pairs\n",
    "    win_summary[\"lagged_corr\"] = {}\n",
    "    for (a, b) in feature_pairs:\n",
    "        x_r = real_orig[i, :, a]; y_r = real_orig[i, :, b]\n",
    "        x_s = synth_inv[i, :, a]; y_s = synth_inv[i, :, b]\n",
    "        lags, corr_r = lagged_corr(x_r, y_r)\n",
    "        _, corr_s = lagged_corr(x_s, y_s)\n",
    "        # plot\n",
    "        fig, ax = plt.subplots(figsize=(8, 3))\n",
    "        ax.plot(lags, corr_r, label=f\"Real {FEATURE_NAMES[a]} vs {FEATURE_NAMES[b]}\")\n",
    "        ax.plot(lags, corr_s, linestyle='--', label=f\"Synth {FEATURE_NAMES[a]} vs {FEATURE_NAMES[b]}\")\n",
    "        ax.axvline(0, color='k', linewidth=0.5)\n",
    "        ax.set_xlabel(\"lag\")\n",
    "        ax.set_ylabel(\"correlation\")\n",
    "        ax.legend()\n",
    "        fig_path = os.path.join(OUT_DIR, f\"lagcorr_win{i}_feat{a}_{a}_feat{b}_{b}.png\")\n",
    "        fig.savefig(fig_path, dpi=200, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "        win_summary[\"lagged_corr\"][f\"{FEATURE_NAMES[a]}__{FEATURE_NAMES[b]}\"] = {\n",
    "            \"lags\": lags.tolist(),\n",
    "            \"corr_real\": corr_r.tolist(),\n",
    "            \"corr_synth\": corr_s.tolist(),\n",
    "            \"plot\": fig_path\n",
    "        }\n",
    "\n",
    "    summary[\"windows\"].append(win_summary)\n",
    "\n",
    "# Save summary JSON\n",
    "summary_path = os.path.join(OUT_DIR, \"diagnostics_summary.json\")\n",
    "with open(summary_path, \"w\") as ff:\n",
    "    json.dump(summary, ff, indent=2)\n",
    "\n",
    "print(\"Diagnostics complete. Plots & JSON summary saved to:\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7ce238",
   "metadata": {},
   "source": [
    "## Notes & tuning tips\n",
    "- `PERIOD` (24) assumes hourly data with daily seasonality; change if your sampling is different.\n",
    "- `CHANGEPOINT_PEN` is the ruptures penalty: increase to get fewer cps, decrease to get more.\n",
    "- If images are large or you want interactive exploration, consider plotting inline and inspecting specific windows before saving.\n",
    "- For a quicker debug run, reduce `EXAMPLES` or `D` (feature loop).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
